#!/usr/bin/env node

import { Pool } from 'pg';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configura√ß√£o da conex√£o usando o banco Neon correto
const DATABASE_URL = "postgresql://neondb_owner:npg_wqC0LP7yRHlT@ep-small-resonance-a45diqst-pooler.us-east-1.aws.neon.tech/neondb?sslmode=require";

const pool = new Pool({
  connectionString: DATABASE_URL,
  ssl: {
    rejectUnauthorized: false
  }
});

// Fun√ß√£o para criar diret√≥rio de backup
function ensureBackupDirectory() {
  const backupDir = path.join(__dirname, 'backup');
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
    console.log('‚úì Diret√≥rio /backup criado');
  }
  return backupDir;
}

// Fun√ß√£o para listar todas as tabelas do banco
async function listAllTables() {
  const client = await pool.connect();
  try {
    const query = `
      SELECT table_name 
      FROM information_schema.tables 
      WHERE table_schema = 'public' 
      AND table_type = 'BASE TABLE'
      ORDER BY table_name;
    `;
    const result = await client.query(query);
    return result.rows.map(row => row.table_name);
  } finally {
    client.release();
  }
}

// Fun√ß√£o para obter a estrutura de uma tabela (DDL)
async function getTableStructure(tableName) {
  const client = await pool.connect();
  try {
    // Obter colunas da tabela
    const columnsQuery = `
      SELECT 
        column_name,
        data_type,
        is_nullable,
        column_default,
        character_maximum_length,
        numeric_precision,
        numeric_scale
      FROM information_schema.columns 
      WHERE table_schema = 'public' 
      AND table_name = $1
      ORDER BY ordinal_position;
    `;
    const columnsResult = await client.query(columnsQuery, [tableName]);
    
    // Obter constraints (chaves prim√°rias, √∫nicas, etc.)
    const constraintsQuery = `
      SELECT 
        tc.constraint_name,
        tc.constraint_type,
        ccu.column_name
      FROM information_schema.table_constraints tc
      JOIN information_schema.constraint_column_usage ccu 
        ON tc.constraint_name = ccu.constraint_name
        AND tc.table_schema = ccu.table_schema
        AND tc.table_name = ccu.table_name
      WHERE tc.table_schema = 'public' 
      AND tc.table_name = $1;
    `;
    const constraintsResult = await client.query(constraintsQuery, [tableName]);
    
    return {
      columns: columnsResult.rows,
      constraints: constraintsResult.rows
    };
  } finally {
    client.release();
  }
}

// Fun√ß√£o para exportar dados de uma tabela
async function exportTableData(tableName) {
  const client = await pool.connect();
  try {
    // Contar registros
    const countResult = await client.query(`SELECT COUNT(*) as count FROM "${tableName}"`);
    const totalRecords = parseInt(countResult.rows[0].count);
    
    if (totalRecords === 0) {
      console.log(`‚ö†Ô∏è  Tabela ${tableName}: 0 registros (pulando)`);
      return { success: true, records: 0 };
    }
    
    // Exportar todos os dados
    const dataResult = await client.query(`SELECT * FROM "${tableName}"`);
    
    return {
      success: true,
      records: totalRecords,
      data: dataResult.rows
    };
  } catch (error) {
    console.error(`‚ùå Erro ao exportar dados da tabela ${tableName}:`, error.message);
    return { success: false, error: error.message };
  } finally {
    client.release();
  }
}

// Fun√ß√£o para gerar SQL INSERT a partir dos dados
function generateInsertSQL(tableName, data, structure) {
  if (!data || data.length === 0) {
    return `-- Tabela ${tableName}: sem dados\n`;
  }
  
  const columns = Object.keys(data[0]);
  let sql = `-- Backup da tabela: ${tableName}\n`;
  sql += `-- Total de registros: ${data.length}\n`;
  sql += `-- Data do backup: ${new Date().toISOString()}\n\n`;
  
  // Desabilitar triggers e constraints temporariamente
  sql += `-- Desabilitar triggers\n`;
  sql += `ALTER TABLE "${tableName}" DISABLE TRIGGER ALL;\n\n`;
  
  // Gerar INSERTs em lotes de 100 registros
  const batchSize = 100;
  for (let i = 0; i < data.length; i += batchSize) {
    const batch = data.slice(i, i + batchSize);
    
    sql += `INSERT INTO "${tableName}" (${columns.map(col => `"${col}"`).join(', ')}) VALUES\n`;
    
    const values = batch.map(row => {
      const rowValues = columns.map(col => {
        const value = row[col];
        if (value === null) return 'NULL';
        if (typeof value === 'string') {
          return `'${value.replace(/'/g, "''")}'`;
        }
        if (typeof value === 'boolean') return value ? 'true' : 'false';
        if (value instanceof Date) return `'${value.toISOString()}'`;
        if (typeof value === 'object') return `'${JSON.stringify(value).replace(/'/g, "''")}'`;
        return value;
      });
      return `(${rowValues.join(', ')})`;
    });
    
    sql += values.join(',\n');
    sql += ';\n\n';
  }
  
  // Reabilitar triggers
  sql += `-- Reabilitar triggers\n`;
  sql += `ALTER TABLE "${tableName}" ENABLE TRIGGER ALL;\n\n`;
  
  return sql;
}

// Fun√ß√£o principal de backup
async function performBackup() {
  console.log('üöÄ Iniciando backup completo do banco de dados...\n');
  
  try {
    // Verificar conex√£o
    const client = await pool.connect();
    const dbResult = await client.query('SELECT current_database(), current_user, version()');
    console.log(`‚úì Conectado ao banco: ${dbResult.rows[0].current_database}`);
    console.log(`‚úì Usu√°rio: ${dbResult.rows[0].current_user}`);
    client.release();
    
    // Criar diret√≥rio de backup
    const backupDir = ensureBackupDirectory();
    
    // Listar todas as tabelas
    console.log('\nüìã Listando tabelas do banco...');
    const tables = await listAllTables();
    console.log(`‚úì Encontradas ${tables.length} tabelas: ${tables.join(', ')}\n`);
    
    if (tables.length === 0) {
      console.log('‚ö†Ô∏è  Nenhuma tabela encontrada no banco!');
      return;
    }
    
    // Backup de cada tabela
    const results = [];
    let totalRecords = 0;
    
    for (const tableName of tables) {
      console.log(`üì¶ Processando tabela: ${tableName}`);
      
      try {
        // Obter estrutura da tabela
        const structure = await getTableStructure(tableName);
        
        // Exportar dados
        const exportResult = await exportTableData(tableName);
        
        if (exportResult.success) {
          // Salvar como JSON (para estrutura de dados)
          const jsonFile = path.join(backupDir, `backup_${tableName}.json`);
          const jsonData = {
            tableName,
            timestamp: new Date().toISOString(),
            recordCount: exportResult.records,
            structure: structure,
            data: exportResult.data || []
          };
          fs.writeFileSync(jsonFile, JSON.stringify(jsonData, null, 2));
          
          // Salvar como SQL (para restaura√ß√£o direta)
          const sqlFile = path.join(backupDir, `backup_${tableName}.sql`);
          const sqlContent = generateInsertSQL(tableName, exportResult.data, structure);
          fs.writeFileSync(sqlFile, sqlContent);
          
          console.log(`  ‚úì ${exportResult.records} registros salvos em:`);
          console.log(`    - ${jsonFile}`);
          console.log(`    - ${sqlFile}`);
          
          totalRecords += exportResult.records;
          results.push({ table: tableName, success: true, records: exportResult.records });
        } else {
          console.log(`  ‚ùå Falha no backup: ${exportResult.error}`);
          results.push({ table: tableName, success: false, error: exportResult.error });
        }
      } catch (error) {
        console.error(`  ‚ùå Erro inesperado na tabela ${tableName}:`, error.message);
        results.push({ table: tableName, success: false, error: error.message });
      }
      
      console.log(''); // Linha em branco para separar
    }
    
    // Criar arquivo de resumo
    const summaryFile = path.join(backupDir, 'backup_summary.json');
    const summary = {
      timestamp: new Date().toISOString(),
      database: dbResult.rows[0].current_database,
      totalTables: tables.length,
      totalRecords: totalRecords,
      results: results,
      successfulTables: results.filter(r => r.success).length,
      failedTables: results.filter(r => !r.success).length
    };
    fs.writeFileSync(summaryFile, JSON.stringify(summary, null, 2));
    
    // Resumo final
    console.log('üìä RESUMO DO BACKUP:');
    console.log(`‚úì Total de tabelas: ${tables.length}`);
    console.log(`‚úì Backup bem-sucedido: ${summary.successfulTables}`);
    console.log(`‚úì Total de registros: ${totalRecords.toLocaleString()}`);
    if (summary.failedTables > 0) {
      console.log(`‚ùå Falhas: ${summary.failedTables}`);
    }
    console.log(`üìÅ Arquivos salvos em: ${backupDir}`);
    console.log(`üìã Resumo detalhado: ${summaryFile}`);
    
    console.log('\nüéâ Backup conclu√≠do com sucesso!');
    
  } catch (error) {
    console.error('üí• Erro cr√≠tico durante o backup:', error);
    process.exit(1);
  }
}

// Fun√ß√£o para fechar conex√µes
async function cleanup() {
  try {
    await pool.end();
    console.log('‚úì Conex√µes com o banco fechadas');
  } catch (error) {
    console.error('Erro ao fechar conex√µes:', error);
  }
}

// Tratamento de sinais para limpeza
process.on('SIGINT', async () => {
  console.log('\n‚ö†Ô∏è  Interrup√ß√£o detectada, fechando conex√µes...');
  await cleanup();
  process.exit(0);
});

process.on('SIGTERM', async () => {
  console.log('\n‚ö†Ô∏è  Termina√ß√£o detectada, fechando conex√µes...');
  await cleanup();
  process.exit(0);
});

// Executar backup
if (import.meta.url === `file://${process.argv[1]}`) {
  performBackup()
    .then(() => {
      return cleanup();
    })
    .then(() => {
      console.log('‚úÖ Script finalizado com sucesso');
      process.exit(0);
    })
    .catch((error) => {
      console.error('üí• Erro fatal:', error);
      cleanup().finally(() => process.exit(1));
    });
}

export { performBackup, cleanup };